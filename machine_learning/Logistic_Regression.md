# Logistic Regression

## 로지스틱 회귀란?

데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 **분류해주는 지도 학습 알고리즘**

설명변수(독립변수, X)와 범주형 목표변수(종속변수, Y) 간의 관계를 모형화하여 목표변수를 분석하거나 분류하는 통계적 방법론

## 로지스틱 회귀의 장단점

### 로지스틱 회귀의 장점

- 회귀 계수의 해석이 가능
- 클래스에 속할 확률 추정함
    - 확률 자체에 관심이 있는 위험도 분석과 같은 분야에서 용이
- 저차원에서 과적합 가능성이 적음
    - 저차원 자료에서 데이터 샘플수가 충분하면 과적합이 덜 일어남
- 분류 문제에서 베이스 모형으로 활용 가능
    - 특정 분류 모형의 성능을 비교 평가하고 싶을 때 비교 모형으로 사용 가능

### 로지스틱 회귀의 단점

- 분류 경계가 선형
- 이상치에 민감

## 로지스틱 회귀 모델의 탐색방법

- [시그모이드(Sigmoid) 함수](https://icim.nims.re.kr/post/easyMath/64)
    
    바이너리 로지스틱 회귀에 주로 사용. 
    
    시그모이드 함수는 결과 값을 0,1로 반환
    
    ⇒ 두 가지로 분류할 때 유용
    
- [소프트맥스(Softmax) 함수](https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221021710286&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F)
    
    softmax 함수 또한 활성화 함수
    
    여러개를 분류하는데 특화
    
    softmax는 출력값들이 정규화가 되어있기 때문에 결과값들의 합은 1을 나타넴
    
    ex) A 0.2 / B 0.2 / C 0.6 -> C가 될 확률이 60%
    
- 최대 우도 추정법
    
    시그모이드 함수를 최적화 가능
    
    어떤 확률변수에서 표집한 값들을 토대로 그 확률변수의 모수를 구하는 방법
    
    어떤 모수가 주어졌을 때, 원하는 값들이 나올 가능도를 최대로 만드는 모수를 선택하는 방법
    

## 로지스틱 회귀 주요 용어

- 오즈 (odds) : ‘실패’(0)에 대한 ‘성공’(1)의 비율
- 로짓 (logit) : ±∞의 범위에서 어떤 클래스에 속할 확률을 결정하는 함수
- 로그 오즈 (log odds) : 변환 모델(선형)의 종속 변수, 이 값을 통해 확률을 구함
